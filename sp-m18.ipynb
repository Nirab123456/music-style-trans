{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fec4a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WindowsPath' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m loader = DataLoader(dataset, batch_size=\u001b[32m1\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Retrieve a sample\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m sample = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IS_TRACK_ID:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded sample with track_id:\u001b[39m\u001b[33m\"\u001b[39m, sample[\u001b[33m'\u001b[39m\u001b[33mtrack_id\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rifat\\miniconda3\\envs\\sml\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rifat\\miniconda3\\envs\\sml\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rifat\\miniconda3\\envs\\sml\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\music\\music-style-trans\\process_musdb18\\audio_adapter.py:151\u001b[39m, in \u001b[36mAudioDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    148\u001b[39m     file_path = \u001b[38;5;28mself\u001b[39m.audio_dir / file_path\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# Load audio, convert to stereo and compute spectrogram\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m waveform, sr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maudio_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m waveform = to_stereo(waveform)\n\u001b[32m    153\u001b[39m spec = compute_spectrogram(waveform)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\music\\music-style-trans\\process_musdb18\\audio_adapter.py:19\u001b[39m, in \u001b[36mSimpleAudioIO.load\u001b[39m\u001b[34m(self, path, sample_rate, duration)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: Union[\u001b[38;5;28mstr\u001b[39m, Path], sample_rate: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, duration: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     path_bytes: \u001b[38;5;28mbytes\u001b[39m = \u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) + \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     20\u001b[39m     c_path: cython.p_char = path_bytes  \u001b[38;5;66;03m# C-style string (if needed for some C functions)\u001b[39;00m\n\u001b[32m     22\u001b[39m     waveform, sr = torchaudio.load(c_path, normalize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'WindowsPath' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from process_musdb18 import AudioDatasetFolder\n",
    "COMPONENT_MAP = [\"mixture\",\"drums\",\"bass\",\"other_accompaniment\",\"vocals\" ]\n",
    "\n",
    "# Create dataset instance.\n",
    "# Note: Adjust audio_dir if the file paths in your CSV are relative to a different base folder.\n",
    "IS_TRACK_ID = True\n",
    "dataset = AudioDatasetFolder(\n",
    "    csv_file='output_stems/musdb18_index_20250408_121813.csv',\n",
    "    audio_dir='.',  # or adjust to your actual base audio directory\n",
    "    components = COMPONENT_MAP,\n",
    "    sample_rate=44100,\n",
    "    duration=5.0,  # Load only the first 10 seconds\n",
    "    is_track_id = IS_TRACK_ID,\n",
    ")\n",
    "\n",
    "# Create a DataLoader to iterate through the dataset.\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Retrieve a sample\n",
    "sample = next(iter(loader))\n",
    "\n",
    "if IS_TRACK_ID:\n",
    "    print(\"Loaded sample with track_id:\", sample['track_id'])\n",
    "\n",
    "# For example, plot the spectrogram for the 'mixture' component.\n",
    "# Since the computed spectrogram is stereo ([channels, freq, time]),\n",
    "# we extract the first channel (index 0) to get a 2D array [freq, time].\n",
    "spec = sample['mixture'][0, 0]  # [batch, channels, freq, time] -> select first sample and first channel\n",
    "\n",
    "plt.imshow(spec.detach().numpy(), origin='lower', aspect='auto',cmap='Dark2_r')\n",
    "plt.title(\"Spectrogram (mixture)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency Bin\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753febc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Downloading Cython-3.0.12-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Downloading Cython-3.0.12-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.3/2.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 6.5 MB/s eta 0:00:00\n",
      "Installing collected packages: cython\n",
      "Successfully installed cython-3.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip install cython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f879bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528d50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
