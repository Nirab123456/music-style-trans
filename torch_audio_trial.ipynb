{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc3e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from process_sml import (\n",
    "    AudioDatasetFolder, Compose, RandomTimeCrop, RandomTimeStretch,\n",
    "    RandomPitchShift, RandomNoise, RandomDistortion, RandomVolume,\n",
    "    compute_waveform, compute_spectrogram\n",
    ")\n",
    "import torch\n",
    "import torchaudio\n",
    "import sounddevice as sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1030934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f756e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = \"pre_saved_tensors\"\n",
    "# Define cache path\n",
    "waveform_cache_path = f\"{root}/cached_waveform.pt\"\n",
    "spec_cache_path = f\"{root}/cached_spec.pt\"\n",
    "\n",
    "os.mkdir(root)\n",
    "\n",
    "# Check if already cached\n",
    "if os.path.exists(waveform_cache_path) and os.path.exists(spec_cache_path):\n",
    "    print(\"Loading from cache...\")\n",
    "    waveform = torch.load(waveform_cache_path)\n",
    "    spec = torch.load(spec_cache_path)\n",
    "else:\n",
    "    print(\"Processing from raw MP3...\")\n",
    "    waveform, sample_rate = torchaudio.load(r\"C:\\Users\\rifat\\Downloads\\Music\\super-saw-bass-37512.mp3\")\n",
    "\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "        sample_rate = 16000\n",
    "\n",
    "    # Take first 5 seconds\n",
    "    num_samples = sample_rate * 5\n",
    "    waveform = waveform[:, :num_samples]\n",
    "\n",
    "    # Save waveform\n",
    "    torch.save(waveform, waveform_cache_path)\n",
    "\n",
    "    # Compute spectrogram and save\n",
    "    spec = compute_spectrogram(waveform)\n",
    "    torch.save(spec, spec_cache_path)\n",
    "\n",
    "# Optional: Play audio\n",
    "# Audio(waveform.numpy(), rate=16000)\n",
    "\n",
    "# Show shape\n",
    "print(f\"Shape of 5-second noise spectrogram: {spec.abs().shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae183b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the computed spectogram without megnititude : torch.Size([2, 1025, 157])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spec = torch.load(\"pre_saved_tensors/cached_spec.pt\")\n",
    "spec = spec.abs()\n",
    "print(f\"shape of the computed spectogram without megnititude : {spec.shape}\")\n",
    "wav = compute_waveform(spec)\n",
    "\n",
    "# Make sure wav is 1D (mono) or 2D (2, N) (stereo)\n",
    "def prepare_for_playback(wav: torch.Tensor) -> torch.Tensor:\n",
    "    if wav.dim() == 2:\n",
    "        # shape: (channels, time)\n",
    "        if wav.size(0) > 2:\n",
    "            wav = wav[:2]  # take first two channels only\n",
    "        return wav\n",
    "    elif wav.dim() == 1:\n",
    "        return wav\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected waveform shape\")\n",
    "\n",
    "\n",
    "# Make sure wav is 1D (mono) or 2D (2, N) (stereo)\n",
    "def prepare_for_playback(wav: torch.Tensor) -> torch.Tensor:\n",
    "    if wav.dim() == 2:\n",
    "        # shape: (channels, time)\n",
    "        if wav.size(0) > 2:\n",
    "            wav = wav[:2]  # take first two channels only\n",
    "        return wav\n",
    "    elif wav.dim() == 1:\n",
    "        return wav\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected waveform shape\")\n",
    "\n",
    "# Example\n",
    "\n",
    "# Fix shape for playback\n",
    "wav = prepare_for_playback(wav)\n",
    "\n",
    "# Convert to numpy and transpose if stereo\n",
    "wav_np = wav.cpu().numpy()\n",
    "if wav_np.ndim == 2:\n",
    "    wav_np = wav_np.T  # (channels, time) → (time, channels)\n",
    "\n",
    "# Play\n",
    "sd.play(wav_np, samplerate=16000)\n",
    "sd.wait()\n",
    "\n",
    "\n",
    "# Fix shape for playback\n",
    "wav = prepare_for_playback(wav)\n",
    "\n",
    "# Convert to numpy and transpose if stereo\n",
    "wav_np = wav.cpu().numpy()\n",
    "if wav_np.ndim == 2:\n",
    "    wav_np = wav_np.T  # (channels, time) → (time, channels)\n",
    "\n",
    "# Play\n",
    "sd.play(wav_np, samplerate=16000)\n",
    "sd.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8182b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"output.wav\", wav, sample_rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNoise:\n",
    "    def __init__(self, snr_db: float = 10.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            snr_db (float): Desired Signal-to-Noise Ratio in dB. Lower = noisier.\n",
    "        \"\"\"\n",
    "        self.snr_db = snr_db\n",
    "\n",
    "    def __call__(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        # Generate Gaussian noise with the same shape\n",
    "        noise = torch.randn_like(waveform)\n",
    "\n",
    "        # Convert SNR to a tensor\n",
    "        snr = torch.tensor([self.snr_db], device=waveform.device)\n",
    "\n",
    "        # Apply add_noise with broadcasting\n",
    "        noisy_waveform = torchaudio.functional.add_noise(waveform, noise, snr)\n",
    "\n",
    "        return noisy_waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a148f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sample_noise\\noise_01.wav\n",
      "Processing: sample_noise\\noise_02.mp3\n",
      "Processing: sample_noise\\noise_03.mp3\n",
      "Processing: sample_noise\\noise_05.mp3\n",
      "Processing: sample_noise\\noise_06.mp3\n",
      "Processing: sample_noise\\noise_08.mp3\n",
      "Processing: sample_noise\\noise_09.mp3\n",
      "Processing: sample_noise\\noise_10.mp3\n",
      "Processing: sample_noise\\noise_11.mp3\n",
      "Processing: sample_noise\\noise_12.mp3\n",
      "Processing: sample_noise\\noise_13.mp3\n",
      "Processing: sample_noise\\noise_14.mp3\n",
      "Processing: sample_noise\\noise_15.mp3\n",
      "Processing: sample_noise\\noise_16.mp3\n",
      "Processing: sample_noise\\noise_17.mp3\n",
      "Processing: sample_noise\\noise_18.mp3\n",
      "Processing: sample_noise\\noise_19.mp3\n",
      "Processing: sample_noise\\noise_20.mp3\n",
      "\n",
      "✅ All audio files concatenated and saved to output.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "\n",
    "# Parameters\n",
    "input_dir = \"sample_noise\"\n",
    "output_file = \"output.wav\"\n",
    "target_sample_rate = 16000  # Change as needed\n",
    "target_channels = 1         # Mono output\n",
    "\n",
    "# Helper function to ensure uniform sample rate and channels\n",
    "def process_audio(file_path, target_sr, target_channels):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "    # Convert to mono if needed\n",
    "    if waveform.shape[0] != target_channels:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "    # Resample if needed\n",
    "    if sample_rate != target_sr:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sr)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    return waveform\n",
    "\n",
    "# Load and concatenate all audio files\n",
    "all_waveforms = []\n",
    "\n",
    "for filename in sorted(os.listdir(input_dir)):\n",
    "    if filename.endswith(('.mp3', '.wav')):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "        print(f\"Processing: {filepath}\")\n",
    "        audio = process_audio(filepath, target_sample_rate, target_channels)\n",
    "        all_waveforms.append(audio)\n",
    "\n",
    "# Concatenate all waveforms along the time axis\n",
    "concatenated = torch.cat(all_waveforms, dim=1)\n",
    "\n",
    "# Save to output .wav file\n",
    "torchaudio.save(output_file, concatenated, sample_rate=target_sample_rate)\n",
    "\n",
    "print(f\"\\n✅ All audio files concatenated and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483570a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\rifat\\miniconda3\\envs\\mlweb\\lib\\site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
