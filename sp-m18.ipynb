{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f744002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "from typing import Dict\n",
    "import torchaudio\n",
    "# Import missing modules for optimization\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Import the UNet model and the training function from the training module.\n",
    "\n",
    "from train_sml import UNet, train_model_source_separation\n",
    "import torch.nn as nn\n",
    "# Import our custom dataset and augmentation pipeline.\n",
    "from process_sml import AudioDatasetFolder, Compose, RandomTimeCrop, RandomTimeStretch, RandomPitchShift, RandomNoise, RandomDistortion, RandomVolume,compute_waveform,to_stereo,compute_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a540e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a198bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "augmentation_pipeline = Compose([\n",
    "    RandomTimeCrop(target_time=512),\n",
    "    # RandomTimeStretch(factor_range=(0.9, 1.1)),\n",
    "    RandomPitchShift(shift_range=(-1.0, 1.0)),\n",
    "    RandomNoise(noise_std=0.05),\n",
    "    RandomDistortion(gamma_range=(0.8, 1.2)),\n",
    "    RandomVolume(volume_range=(0.8, 1.2))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa21788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the component map for the dataset.\n",
    "COMPONENT_MAP = [\"mixture\", \"drums\", \"bass\", \"other_accompaniment\", \"vocals\"]\n",
    "IS_TRACK_ID = True\n",
    "\n",
    "# Set random seeds for reproducibility.\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Choose device early.\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create the dataset.\n",
    "dataset_multi = AudioDatasetFolder(\n",
    "    csv_file='output_stems/musdb18_index_20250408_121813.csv',\n",
    "    audio_dir='.',  # adjust as needed\n",
    "    components=COMPONENT_MAP,\n",
    "    sample_rate=16000,\n",
    "    duration=5.0,\n",
    "    # transform=augmentation_pipeline,  # list of transforms\n",
    "    is_track_id=IS_TRACK_ID,\n",
    "    input_name= \"mixture\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4141b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1025, 157])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset_multi.__getitem__(3)['mixture']\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b6214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "\n",
    "# Make sure wav is 1D (mono) or 2D (2, N) (stereo)\n",
    "def prepare_for_playback(wav: torch.Tensor) -> torch.Tensor:\n",
    "    if wav.dim() == 2:\n",
    "        # shape: (channels, time)\n",
    "        if wav.size(0) > 2:\n",
    "            wav = wav[:2]  # take first two channels only\n",
    "        return wav\n",
    "    elif wav.dim() == 1:\n",
    "        return wav\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected waveform shape\")\n",
    "\n",
    "# Example\n",
    "x = dataset_multi.__getitem__(3)\n",
    "wav = compute_waveform(x['mixture'])\n",
    "\n",
    "# Fix shape for playback\n",
    "wav = prepare_for_playback(wav)\n",
    "\n",
    "# Convert to numpy and transpose if stereo\n",
    "wav_np = wav.cpu().numpy()\n",
    "if wav_np.ndim == 2:\n",
    "    wav_np = wav_np.T  # (channels, time) â†’ (time, channels)\n",
    "\n",
    "# Play\n",
    "sd.play(wav_np, samplerate=16000)\n",
    "sd.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004e0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into train and validation (e.g., 80/20 split).\n",
    "dataset_size = len(dataset_multi)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(0.8 * dataset_size)\n",
    "train_indices, val_indices = indices[:split], indices[split:]\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "train_loader = DataLoader(dataset_multi, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset_multi, batch_size=32, sampler=val_sampler)\n",
    "dataloaders: Dict[str, DataLoader] = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "# -------------------------------\n",
    "# Model Integration\n",
    "# -------------------------------\n",
    "# For source separation, the model is expected to take the mixture spectrogram as input,\n",
    "# and output separated source spectrograms corresponding to each target.\n",
    "# --- Since the mixture is stereo, we initialize the UNet with in_channels=2 ---\n",
    "model = UNet(in_channels=2)\n",
    "\n",
    "# Define the label names (target keys) for source separation.\n",
    "label_names = [\"drums\", \"bass\", \"other_accompaniment\", \"vocals\"]\n",
    "\n",
    "# Prepare the final convolution layers for each target output.\n",
    "# Here we assume that the decoder produces feature maps with 16 channels.\n",
    "for key in label_names:\n",
    "    model.final_convs[key] = nn.Conv2d(16, 2, kernel_size=1)\n",
    "\n",
    "# IMPORTANT: Move the entire model to the device after adding the final conv layers.\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2dc1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "\n",
    "# Your input\n",
    "input_shape = (2, 1025, 32)\n",
    "\n",
    "\n",
    "# Summary with all output channels\n",
    "summary(model=model, input_size=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------------------------------------\n",
      "Train Epoch [1/3] Batch [0/4] Loss: 0.9941 LR: 0.001000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Loss Function, Optimizer, Scheduler\n",
    "# -------------------------------\n",
    "# Use L1 loss for source separation.\n",
    "criterion = nn.L1Loss()\n",
    "# Create the optimizer using the model parameters.\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Create a learning rate scheduler.\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# -------------------------------\n",
    "# Train the Model\n",
    "# -------------------------------\n",
    "# Here, the input key is \"mixture\" and label names are defined as above.\n",
    "best_model = train_model_source_separation(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=3,\n",
    "    device=device,\n",
    "    log_dir='./logs',\n",
    "    checkpoint_dir='./checkpoints',\n",
    "    input_name=\"mixture\",  # use \"mixture\" for the input spectrogram from the batch\n",
    "    label_names=label_names,  # list of target keys for separated sources\n",
    "    print_freq=10,\n",
    ")\n",
    "\n",
    "# (Optional) Test or visualize the best_model as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875220f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define an additional simple normalization transform:\n",
    "def normalize_spec(spec: torch.Tensor) -> torch.Tensor:\n",
    "    return (spec - spec.mean()) / (spec.std() + 1e-6)\n",
    "\n",
    "COMPONENT_MAP = [\"mixture\", \"drums\", \"bass\", \"other_accompaniment\", \"vocals\"]\n",
    "\n",
    "IS_TRACK_ID = True\n",
    "dataset_multi = AudioDatasetFolder(\n",
    "    csv_file='output_stems/musdb18_index_20250408_121813.csv',\n",
    "    audio_dir='.',  # adjust as needed\n",
    "    components=COMPONENT_MAP,\n",
    "    sample_rate=16000,\n",
    "    duration=5.0,\n",
    "    is_track_id=IS_TRACK_ID,\n",
    ")\n",
    "\n",
    "loader_multi = DataLoader(dataset_multi, batch_size=32, shuffle=False)\n",
    "sample_multi = next(iter(loader_multi))\n",
    "\n",
    "if IS_TRACK_ID:\n",
    "    print(\"Loaded sample with track_id:\", sample_multi['track_id'])\n",
    "\n",
    "# Plot spectrogram for the 'mixture' component.\n",
    "spec_multi = sample_multi['vocals'][0, 0]  # select first sample and first channel\n",
    "plt.imshow(spec_multi.detach().numpy(), origin='lower', aspect='auto', cmap='Dark2_r')\n",
    "plt.title(\"Spectrogram (mixture) with pitch_shift and normalization\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency Bin\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6664d00",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range in randrange(0, -78974)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m big_tensor = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpre_saved_tensors\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mshuffled_big_noise_spec_tensor.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m big_tensor = torch.load(big_tensor)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m noise_crop = \u001b[43mrandom_noise_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbig_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Convert to spectrogram\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of 5-second noise spectrogram: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_crop.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mrandom_noise_crop\u001b[39m\u001b[34m(tensor, crop_duration, sample_rate)\u001b[39m\n\u001b[32m      8\u001b[39m     tensor = F.pad(tensor, (\u001b[32m0\u001b[39m, pad_size))  \u001b[38;5;66;03m# Pad at the end\u001b[39;00m\n\u001b[32m     10\u001b[39m max_start = tensor.shape[\u001b[32m1\u001b[39m] - crop_size\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m start = \u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_start\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor[:, start:start + crop_size]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rifat\\miniconda3\\envs\\sml\\Lib\\random.py:336\u001b[39m, in \u001b[36mRandom.randint\u001b[39m\u001b[34m(self, a, b)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rifat\\miniconda3\\envs\\sml\\Lib\\random.py:319\u001b[39m, in \u001b[36mRandom.randrange\u001b[39m\u001b[34m(self, start, stop, step)\u001b[39m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m width > \u001b[32m0\u001b[39m:\n\u001b[32m    318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m istart + \u001b[38;5;28mself\u001b[39m._randbelow(width)\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mempty range in randrange(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Non-unit step argument supplied.\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m istep > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: empty range in randrange(0, -78974)"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def random_noise_crop(tensor, crop_duration=5.0, sample_rate=16000):\n",
    "    crop_size = int(crop_duration * sample_rate)\n",
    "\n",
    "    if tensor.shape[1] < crop_size:\n",
    "        pad_size = crop_size - tensor.shape[1]\n",
    "        tensor = F.pad(tensor, (0, pad_size))  # Pad at the end\n",
    "    \n",
    "    max_start = tensor.shape[1] - crop_size\n",
    "    start = random.randint(0, max_start)\n",
    "    return tensor[:, start:start + crop_size]\n",
    "\n",
    "big_tensor = r\"pre_saved_tensors\\shuffled_big_noise_spec_tensor.pt\"\n",
    "big_tensor = torch.load(big_tensor)\n",
    "noise_crop = random_noise_crop(big_tensor)\n",
    "# Convert to spectrogram\n",
    "print(f\"Shape of 5-second noise spectrogram: {noise_crop.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e65e442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 5-second noise spectrogram: torch.Size([2, 1025, 157])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def random_noise_crop(tensor, crop_duration=5.0, sample_rate=16000):\n",
    "    crop_size = int(crop_duration * sample_rate)\n",
    "    max_start = tensor.shape[1] - crop_size\n",
    "    start = random.randint(0, max_start)\n",
    "    return tensor[:, start:start + crop_size]\n",
    "\n",
    "\n",
    "big_tensor = r\"pre_saved_tensors\\shuffled_big_noise_tensor.pt\"\n",
    "big_tensor = torch.load(big_tensor)\n",
    "\n",
    "noise_crop = random_noise_crop(big_tensor)\n",
    "# Convert to spectrogram\n",
    "spec = compute_spectrogram(noise_crop)\n",
    "print(f\"Shape of 5-second noise spectrogram: {spec.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d60868",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range in randrange(0, -78974)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load waveform\u001b[39;00m\n\u001b[32m     12\u001b[39m wave_tensor = torch.load(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpre_saved_tensors\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mshuffled_big_noise_SPEC_tensor.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# shape: [2, N]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m wave_crop = \u001b[43mrandom_waveform_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwave_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_duration\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Compute spectrogram\u001b[39;00m\n\u001b[32m     16\u001b[39m spec = compute_spectrogram(wave_crop)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mrandom_waveform_crop\u001b[39m\u001b[34m(tensor, crop_duration, sample_rate)\u001b[39m\n\u001b[32m      5\u001b[39m     tensor = F.pad(tensor, (\u001b[32m0\u001b[39m, crop_size - tensor.shape[\u001b[32m1\u001b[39m]))\n\u001b[32m      6\u001b[39m max_start = tensor.shape[\u001b[32m1\u001b[39m] - crop_size\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m start = \u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_start\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor[:, start:start + crop_size]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rifat\\miniconda3\\envs\\sml\\Lib\\random.py:336\u001b[39m, in \u001b[36mRandom.randint\u001b[39m\u001b[34m(self, a, b)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rifat\\miniconda3\\envs\\sml\\Lib\\random.py:319\u001b[39m, in \u001b[36mRandom.randrange\u001b[39m\u001b[34m(self, start, stop, step)\u001b[39m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m width > \u001b[32m0\u001b[39m:\n\u001b[32m    318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m istart + \u001b[38;5;28mself\u001b[39m._randbelow(width)\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mempty range in randrange(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Non-unit step argument supplied.\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m istep > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: empty range in randrange(0, -78974)"
     ]
    }
   ],
   "source": [
    "def random_waveform_crop(tensor, crop_duration=5.0, sample_rate=16000):\n",
    "    \"\"\"Crop a waveform to fixed duration before computing spectrogram.\"\"\"\n",
    "    crop_size = int(crop_duration * sample_rate)\n",
    "    if tensor.shape[1] < crop_size:\n",
    "        tensor = F.pad(tensor, (0, crop_size - tensor.shape[1]))\n",
    "    max_start = tensor.shape[1] - crop_size\n",
    "    start = random.randint(0, max_start)\n",
    "    return tensor[:, start:start + crop_size]\n",
    "\n",
    "\n",
    "# Load waveform\n",
    "wave_tensor = torch.load(r\"pre_saved_tensors\\shuffled_big_noise_SPEC_tensor.pt\")  # shape: [2, N]\n",
    "wave_crop = random_waveform_crop(wave_tensor, crop_duration=5.0)\n",
    "\n",
    "# Compute spectrogram\n",
    "spec = compute_spectrogram(wave_crop)\n",
    "print(f\"Shape of 5-second noise spectrogram: {spec.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
